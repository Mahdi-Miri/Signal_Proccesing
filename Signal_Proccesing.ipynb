{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/Mahdi-Miri/Signal_Proccesing-/blob/main/Signal_Proccesing.ipynb",
      "authorship_tag": "ABX9TyPLsAPE9yK16qsTIAZq8VRe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahdi-Miri/Signal_Proccesing/blob/main/Signal_Proccesing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Readig"
      ],
      "metadata": {
        "id": "FTuvlrstUHeC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec8fe35a",
        "outputId": "f1b3db71-0178-4575-e42a-186da817dc39"
      },
      "source": [
        "!pip install obspy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: obspy in /usr/local/lib/python3.12/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.12/dist-packages (from obspy) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.12/dist-packages (from obspy) (1.16.2)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.12/dist-packages (from obspy) (3.10.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from obspy) (5.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from obspy) (75.2.0)\n",
            "Requirement already satisfied: sqlalchemy<2 in /usr/local/lib/python3.12/dist-packages (from obspy) (1.4.54)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from obspy) (4.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from obspy) (2.32.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (2.9.0.post0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<2->obspy) (3.2.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->obspy) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->obspy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->obspy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->obspy) (2025.8.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->obspy) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelling"
      ],
      "metadata": {
        "id": "3yqHTrHlNELT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, BatchNormalization, ReLU, MaxPooling2D,\n",
        "    GlobalAveragePooling2D, TimeDistributed, Dense, Permute, Reshape, Layer\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "xw-UFeFjNI11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Custom Layer Definition with Functional Implementation ---\n",
        "# This layer now has a functional implementation based on the\n",
        "# Auto-Correlation mechanism using Fast Fourier Transform (FFT).\n",
        "class CustomAutocorrelationLayer(Layer):\n",
        "    \"\"\"\n",
        "    A custom layer that calculates the temporal auto-correlation of an input tensor.\n",
        "    It operates on the last axis, which is assumed to be the time dimension.\n",
        "    The calculation is performed efficiently in the frequency domain using FFT.\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(CustomAutocorrelationLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # The input shape is expected to be (Batch, Height, Width, TimeSteps)\n",
        "        # We need to compute auto-correlation along the TimeSteps axis (axis=-1).\n",
        "\n",
        "        # Get the length of the time series\n",
        "        sequence_length = tf.shape(inputs)[-1]\n",
        "\n",
        "        # --- Step 1: Go to Frequency Domain using FFT ---\n",
        "        # Perform Fast Fourier Transform. tf.signal.rfft is used for real-valued inputs.\n",
        "        # The length of the FFT is padded to the next power of 2 for efficiency,\n",
        "        # but for simplicity, we'll use the original length here.\n",
        "        fft_result = tf.signal.rfft(inputs, fft_length=[sequence_length])\n",
        "\n",
        "        # --- Step 2: Compute Power Spectral Density ---\n",
        "        # This is where the correlation is calculated.\n",
        "        # It's done by multiplying the FFT result by its complex conjugate.\n",
        "        # This is equivalent to convolution in the time domain.\n",
        "        power_spectral_density = fft_result * tf.math.conj(fft_result)\n",
        "\n",
        "        # --- Step 3: Go back to Time Domain using Inverse FFT ---\n",
        "        # Perform Inverse Real Fast Fourier Transform to get the auto-correlation series.\n",
        "        autocorr_result = tf.signal.irfft(power_spectral_density, fft_length=[sequence_length])\n",
        "\n",
        "        return autocorr_result\n",
        "\n",
        "    def get_config(self):\n",
        "        # Required for model saving and loading\n",
        "        config = super(CustomAutocorrelationLayer, self).get_config()\n",
        "        return config\n",
        "\n",
        "# --- Full Architecture Definition ---\n",
        "def build_spatio_temporal_model(input_shape=(60, 60, 100)):\n",
        "    \"\"\"\n",
        "    Builds the complete Spatio-Temporal feature extraction model based on the diagram.\n",
        "\n",
        "    Args:\n",
        "        input_shape (tuple): The shape of the input data (Height, Width, TimeSteps).\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: The compiled Keras model.\n",
        "    \"\"\"\n",
        "    # Define the input layer for our spatio-temporal data\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # --- Part 1: Temporal Transformation & Reshaping ---\n",
        "\n",
        "    # Apply the functional autocorrelation layer to find temporal patterns.\n",
        "    # This layer processes each spatial point's time series (60x60 series of length 100).\n",
        "    # Output values now represent the strength of temporal correlations.\n",
        "    temporal_features = CustomAutocorrelationLayer()(inputs)  # Shape: (None, 60, 60, 100)\n",
        "\n",
        "    # Permute the dimensions to bring the time-steps to the front for the next stage.\n",
        "    # (Height, Width, TimeSteps) -> (TimeSteps, Height, Width)\n",
        "    permuted = Permute((3, 1, 2))(temporal_features)  # Shape: (None, 100, 60, 60)\n",
        "\n",
        "    # Reshape to add a 'channels' dimension. Each time-step is now a 60x60x1 image,\n",
        "    # ready to be processed by a 2D CNN.\n",
        "    reshaped = Reshape((100, 60, 60, 1))(permuted)  # Shape: (None, 100, 60, 60, 1)\n",
        "\n",
        "    # --- Part 2: Time-Distributed Spatial Feature Extraction ---\n",
        "\n",
        "    # Define the CNN block that extracts spatial features from a single 60x60 frame.\n",
        "    cnn_block = tf.keras.Sequential([\n",
        "        # Finds low-level features like edges and gradients.\n",
        "        Conv2D(32, kernel_size=(3, 3), padding='same'),\n",
        "        BatchNormalization(),\n",
        "        ReLU(),\n",
        "        # Downsamples the feature map to make representations more robust.\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # Finds higher-level features by combining low-level ones.\n",
        "        Conv2D(64, kernel_size=(3, 3), padding='same'),\n",
        "        BatchNormalization(),\n",
        "        ReLU(),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # Summarizes all spatial features in the frame into a single, fixed-size vector.\n",
        "        GlobalAveragePooling2D()\n",
        "    ], name='internal_cnn_block')\n",
        "\n",
        "    # Apply the defined cnn_block to each of the 100 time-steps independently.\n",
        "    # The output is a sequence of 100 feature vectors, one for each time-step.\n",
        "    time_distributed_cnn = TimeDistributed(cnn_block)(reshaped)  # Shape: (None, 100, 64)\n",
        "\n",
        "    # --- Part 3: Final Transformation ---\n",
        "\n",
        "    # A Dense layer refines the features from the CNN, reducing each feature vector's size to 10.\n",
        "    # It learns combinations of the spatial features.\n",
        "    dense_features = Dense(10, activation='relu')(time_distributed_cnn)  # Shape: (None, 100, 10)\n",
        "\n",
        "    # Final permutation to get the output shape of (Features, TimeSteps).\n",
        "    # This format might be useful for downstream tasks that analyze each feature over time.\n",
        "    final_output = Permute((2, 1))(dense_features)  # Shape: (None, 10, 100)\n",
        "\n",
        "    # Create the final model by defining its inputs and outputs\n",
        "    model = Model(inputs=inputs, outputs=final_output, name='SpatioTemporal_Feature_Extractor')\n",
        "\n",
        "    return model\n",
        "\n",
        "# --- Model Creation, Compilation, and Execution Example ---\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Define the input shape as per the diagram\n",
        "    INPUT_SHAPE = (60, 60, 100)\n",
        "\n",
        "    # Build the model\n",
        "    model = build_spatio_temporal_model(input_shape=INPUT_SHAPE)\n",
        "\n",
        "    # Compile the model. A loss function and optimizer are needed for training.\n",
        "    # For feature extraction, you might not train it, but compilation is a good practice.\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    # Print the model summary to verify the architecture and shapes\n",
        "    print(\"--- Model Summary ---\")\n",
        "    model.summary()\n",
        "\n",
        "    # --- Example of running the model with dummy data ---\n",
        "    print(\"\\n--- Running a test prediction ---\")\n",
        "    # Create a batch of 2 dummy \"videos\" with random data\n",
        "    dummy_data = np.random.rand(2, *INPUT_SHAPE)\n",
        "\n",
        "    # Get the model's prediction\n",
        "    predictions = model.predict(dummy_data)\n",
        "\n",
        "    # Print the shape of the output to confirm it matches the design\n",
        "    print(f\"Input data shape: {dummy_data.shape}\")\n",
        "    print(f\"Final output shape: {predictions.shape}\")\n"
      ],
      "metadata": {
        "id": "o0hhgiZvNFMF",
        "outputId": "476f3009-fa26-4085-c7a3-c83ce76b8638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Model Summary ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"SpatioTemporal_Feature_Extractor\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"SpatioTemporal_Feature_Extractor\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ custom_autocorrelation_layer    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomAutocorrelationLayer</span>)    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                   │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ permute (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│                                 │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                  │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,200</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ permute_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ custom_autocorrelation_layer    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mCustomAutocorrelationLayer\u001b[0m)    │ \u001b[38;5;34m100\u001b[0m)                   │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ permute (\u001b[38;5;33mPermute\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│                                 │ \u001b[38;5;45mNone\u001b[0m)                  │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m1\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m19,200\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │           \u001b[38;5;34m650\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ permute_1 (\u001b[38;5;33mPermute\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,850</span> (77.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,850\u001b[0m (77.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,658</span> (76.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,658\u001b[0m (76.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running a test prediction ---\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step\n",
            "Input data shape: (2, 60, 60, 100)\n",
            "Final output shape: (2, 10, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sYcebQYynz8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##testing"
      ],
      "metadata": {
        "id": "dmn17kIoqnYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Input, Permute, Reshape, Conv2D, BatchNormalization, ReLU, MaxPooling2D, GlobalAveragePooling2D, TimeDistributed, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import obspy\n",
        "from obspy import UTCDateTime, read, read_inventory, Stream, Trace\n",
        "from scipy.signal import correlate\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ==============================================================================\n",
        "#  1. KERAS MODEL DEFINITION\n",
        "# ==============================================================================\n",
        "class CustomAutocorrelationLayer(Layer):\n",
        "    \"\"\"Custom layer to calculate temporal auto-correlation using FFT.\"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(CustomAutocorrelationLayer, self).__init__(**kwargs)\n",
        "    def call(self, inputs):\n",
        "        sequence_length = tf.shape(inputs)[-1]\n",
        "        fft_result = tf.signal.rfft(inputs, fft_length=[sequence_length])\n",
        "        power_spectral_density = fft_result * tf.math.conj(fft_result)\n",
        "        autocorr_result = tf.signal.irfft(power_spectral_density, fft_length=[sequence_length])\n",
        "        return autocorr_result\n",
        "\n",
        "def build_spatio_temporal_model(input_shape=(60, 60, 100)):\n",
        "    \"\"\"Builds the complete Spatio-Temporal feature extraction model.\"\"\"\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # The custom layer is given a name to access its output later\n",
        "    temporal_features = CustomAutocorrelationLayer(name='autocorr_layer')(inputs)\n",
        "    permuted = Permute((3, 1, 2))(temporal_features)\n",
        "    reshaped = Reshape((100, 60, 60, 1))(permuted)\n",
        "    cnn_block = tf.keras.Sequential([\n",
        "        Conv2D(32, (3, 3), padding='same'), BatchNormalization(), ReLU(), MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), padding='same'), BatchNormalization(), ReLU(), MaxPooling2D((2, 2)),\n",
        "        GlobalAveragePooling2D()\n",
        "    ], name='internal_cnn_block')\n",
        "    time_distributed_cnn = TimeDistributed(cnn_block)(reshaped)\n",
        "    dense_features = Dense(10, activation='relu')(time_distributed_cnn)\n",
        "    final_output = Permute((2, 1))(dense_features)\n",
        "    model = Model(inputs=inputs, outputs=final_output, name='SpatioTemporal_Feature_Extractor')\n",
        "    return model\n",
        "\n",
        "# ==============================================================================\n",
        "#  2. DATA PREPARATION FUNCTION\n",
        "# ==============================================================================\n",
        "def prepare_ambient_noise_data(recordings_path, xml_path, station_list, num_days, shape):\n",
        "    \"\"\"Loads data, calculates daily autocorrelations, and formats for the model.\"\"\"\n",
        "    height, width, timesteps = shape\n",
        "    all_autocorrelations = []\n",
        "    print(\"--- Starting Data Preparation ---\")\n",
        "    try:\n",
        "        stream = read(recordings_path)\n",
        "        inventory = read_inventory(os.path.join(xml_path, \"GH.*.xml\"))\n",
        "        start_time = stream[0].stats.starttime\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Could not load data files. Reason: {e}\")\n",
        "        return None\n",
        "    for station_name in station_list:\n",
        "        print(f\"Processing Station: {station_name}\")\n",
        "        station_stream = stream.select(station=station_name)\n",
        "        if not station_stream:\n",
        "            print(f\"  - No data found for station {station_name}. Skipping.\")\n",
        "            continue\n",
        "        for day in range(num_days):\n",
        "            day_start = start_time + day * 86400\n",
        "            st_day = station_stream.slice(starttime=day_start, endtime=day_start + 86400)\n",
        "            if not st_day:\n",
        "                continue\n",
        "            try:\n",
        "                # --- Pre-processing Steps with all fixes ---\n",
        "                st_day.detrend('linear')\n",
        "                st_day.taper(max_percentage=0.05, type=\"hann\")\n",
        "                # Use robust keyword arguments\n",
        "                st_day.remove_response(\n",
        "                    inventory=inventory,\n",
        "                    output=\"VEL\",\n",
        "                    pre_filt=(0.01, 0.05, 45, 50)\n",
        "                )\n",
        "                # Use stable, multi-stage decimation\n",
        "                st_day.decimate(factor=10)\n",
        "                st_day.decimate(factor=10)\n",
        "                st_day.filter('bandpass', freqmin=0.1, freqmax=0.4, zerophase=True)\n",
        "                # Use correct one-bit normalization\n",
        "                for trace in st_day:\n",
        "                    trace.data = np.sign(trace.data)\n",
        "\n",
        "                # --- Autocorrelation ---\n",
        "                trace = st_day[0]\n",
        "                npts = trace.stats.npts\n",
        "                autocorr_data = correlate(trace.data, trace.data, mode='full')[npts-1:]\n",
        "\n",
        "                # --- Finalize Data for Model ---\n",
        "                if len(autocorr_data) > timesteps:\n",
        "                    final_data = autocorr_data[:timesteps]\n",
        "                else:\n",
        "                    padding = np.zeros(timesteps - len(autocorr_data))\n",
        "                    final_data = np.concatenate([autocorr_data, padding])\n",
        "                all_autocorrelations.append(final_data)\n",
        "            except Exception as e:\n",
        "                print(f\"    - Error on day {day+1} for {station_name}: {type(e).__name__} - {e}\")\n",
        "                continue\n",
        "    if not all_autocorrelations:\n",
        "        print(\"ERROR: No data was successfully processed.\")\n",
        "        return None\n",
        "\n",
        "    stacked_signals = np.array(all_autocorrelations)\n",
        "    model_input_data = np.zeros((stacked_signals.shape[0], height, width, timesteps))\n",
        "    model_input_data[:, height // 2, width // 2, :] = stacked_signals\n",
        "    return model_input_data\n",
        "\n",
        "# ==============================================================================\n",
        "#  3. MAIN EXECUTION BLOCK\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    # --- CONFIGURATION: Edit these paths ---\n",
        "    RECORDED_DATA_FILE = \"/content/drive/MyDrive/Signal/2013-01-01-00-00-00.mseed\"\n",
        "    XML_FOLDER_PATH = \"/content/drive/MyDrive/Signal/\"\n",
        "    STATION_NAMES = ['AKOS', 'KLEF', 'KUKU', 'MRON']\n",
        "    NUM_DAYS_TO_PROCESS = 1# Number of days to process for each station\n",
        "    MODEL_SHAPE = (60, 60, 100)\n",
        "    NEW_SAMPLING_RATE = 1.0 # Hz\n",
        "\n",
        "    # --- Step 1: Prepare the data ---\n",
        "    prepared_data = prepare_ambient_noise_data(\n",
        "        recordings_path=RECORDED_DATA_FILE, xml_path=XML_FOLDER_PATH,\n",
        "        station_list=STATION_NAMES, num_days=NUM_DAYS_TO_PROCESS,\n",
        "        shape=MODEL_SHAPE\n",
        "    )\n",
        "\n",
        "    if prepared_data is not None:\n",
        "        print(f\"\\n✅ Data preparation complete. Input shape: {prepared_data.shape}\")\n",
        "\n",
        "        # --- Step 2: Build and Compile Keras Model ---\n",
        "        full_model = build_spatio_temporal_model(input_shape=MODEL_SHAPE)\n",
        "        full_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "        # --- Step 3: Run Visualizations ---\n",
        "        print(\"\\n--- Creating Visualizations ---\")\n",
        "\n",
        "        # VISUALIZATION 1: Heatmap of Final Model Features\n",
        "        print(\"Running full model to generate feature heatmap...\")\n",
        "        predictions = full_model.predict(prepared_data)\n",
        "\n",
        "        # Visualize the features for the first sample (e.g., AKOS, Day 1)\n",
        "        sample_to_visualize = predictions[0]\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        sns.heatmap(sample_to_visualize, cmap='viridis')\n",
        "        plt.title(\"Heatmap of Final Extracted Features (First Sample)\")\n",
        "        plt.xlabel(\"Time Steps\")\n",
        "        plt.ylabel(\"Feature Index\")\n",
        "        plt.show()\n",
        "\n",
        "        # VISUALIZATION 2: Seismic Section Plot of Raw Autocorrelation\n",
        "        print(\"Running intermediate model to generate section plot...\")\n",
        "        intermediate_model = Model(inputs=full_model.input, outputs=full_model.get_layer('autocorr_layer').output)\n",
        "        autocorr_results_4d = intermediate_model.predict(prepared_data)\n",
        "        autocorr_results_1d = autocorr_results_4d[:, MODEL_SHAPE[0] // 2, MODEL_SHAPE[1] // 2, :]\n",
        "\n",
        "        autocorr_stream = Stream()\n",
        "        for i, daily_result in enumerate(autocorr_results_1d):\n",
        "            trace = Trace(data=daily_result)\n",
        "            trace.stats.sampling_rate = NEW_SAMPLING_RATE\n",
        "            # Set a distance value in meters to satisfy the plot function\n",
        "            trace.stats.distance = i * 1000\n",
        "            autocorr_stream.append(trace)\n",
        "\n",
        "        print(\"Displaying section plot...\")\n",
        "        autocorr_stream.plot(\n",
        "            type='section',\n",
        "            recordlength=20,\n",
        "            fillcolors=('red', 'black'),\n",
        "            stack_results=True,\n",
        "            title=\"Raw Autocorrelation from Keras Layer\"\n",
        "        )"
      ],
      "metadata": {
        "id": "YIwoleGOqoaF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}