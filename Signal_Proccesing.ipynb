{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/Mahdi-Miri/Signal_Proccesing-/blob/main/Signal_Proccesing.ipynb",
      "authorship_tag": "ABX9TyMhXSK6BzqzQuGHbIYZ6XV5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahdi-Miri/Signal_Proccesing/blob/main/Signal_Proccesing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Readig"
      ],
      "metadata": {
        "id": "FTuvlrstUHeC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec8fe35a",
        "outputId": "f1b3db71-0178-4575-e42a-186da817dc39"
      },
      "source": [
        "!pip install obspy"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: obspy in /usr/local/lib/python3.12/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.12/dist-packages (from obspy) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.12/dist-packages (from obspy) (1.16.2)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.12/dist-packages (from obspy) (3.10.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from obspy) (5.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from obspy) (75.2.0)\n",
            "Requirement already satisfied: sqlalchemy<2 in /usr/local/lib/python3.12/dist-packages (from obspy) (1.4.54)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from obspy) (4.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from obspy) (2.32.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (2.9.0.post0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<2->obspy) (3.2.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->obspy) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->obspy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->obspy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->obspy) (2025.8.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->obspy) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelling"
      ],
      "metadata": {
        "id": "3yqHTrHlNELT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, BatchNormalization, ReLU, MaxPooling2D,\n",
        "    GlobalAveragePooling2D, TimeDistributed, Dense, Permute, Reshape, Layer\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "xw-UFeFjNI11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Custom Layer Definition with Functional Implementation ---\n",
        "# This layer now has a functional implementation based on the\n",
        "# Auto-Correlation mechanism using Fast Fourier Transform (FFT).\n",
        "class CustomAutocorrelationLayer(Layer):\n",
        "    \"\"\"\n",
        "    A custom layer that calculates the temporal auto-correlation of an input tensor.\n",
        "    It operates on the last axis, which is assumed to be the time dimension.\n",
        "    The calculation is performed efficiently in the frequency domain using FFT.\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(CustomAutocorrelationLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # The input shape is expected to be (Batch, Height, Width, TimeSteps)\n",
        "        # We need to compute auto-correlation along the TimeSteps axis (axis=-1).\n",
        "\n",
        "        # Get the length of the time series\n",
        "        sequence_length = tf.shape(inputs)[-1]\n",
        "\n",
        "        # --- Step 1: Go to Frequency Domain using FFT ---\n",
        "        # Perform Fast Fourier Transform. tf.signal.rfft is used for real-valued inputs.\n",
        "        # The length of the FFT is padded to the next power of 2 for efficiency,\n",
        "        # but for simplicity, we'll use the original length here.\n",
        "        fft_result = tf.signal.rfft(inputs, fft_length=[sequence_length])\n",
        "\n",
        "        # --- Step 2: Compute Power Spectral Density ---\n",
        "        # This is where the correlation is calculated.\n",
        "        # It's done by multiplying the FFT result by its complex conjugate.\n",
        "        # This is equivalent to convolution in the time domain.\n",
        "        power_spectral_density = fft_result * tf.math.conj(fft_result)\n",
        "\n",
        "        # --- Step 3: Go back to Time Domain using Inverse FFT ---\n",
        "        # Perform Inverse Real Fast Fourier Transform to get the auto-correlation series.\n",
        "        autocorr_result = tf.signal.irfft(power_spectral_density, fft_length=[sequence_length])\n",
        "\n",
        "        return autocorr_result\n",
        "\n",
        "    def get_config(self):\n",
        "        # Required for model saving and loading\n",
        "        config = super(CustomAutocorrelationLayer, self).get_config()\n",
        "        return config\n",
        "\n",
        "# --- Full Architecture Definition ---\n",
        "def build_spatio_temporal_model(input_shape=(60, 60, 100)):\n",
        "    \"\"\"\n",
        "    Builds the complete Spatio-Temporal feature extraction model based on the diagram.\n",
        "\n",
        "    Args:\n",
        "        input_shape (tuple): The shape of the input data (Height, Width, TimeSteps).\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: The compiled Keras model.\n",
        "    \"\"\"\n",
        "    # Define the input layer for our spatio-temporal data\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # --- Part 1: Temporal Transformation & Reshaping ---\n",
        "\n",
        "    # Apply the functional autocorrelation layer to find temporal patterns.\n",
        "    # This layer processes each spatial point's time series (60x60 series of length 100).\n",
        "    # Output values now represent the strength of temporal correlations.\n",
        "    temporal_features = CustomAutocorrelationLayer()(inputs)  # Shape: (None, 60, 60, 100)\n",
        "\n",
        "    # Permute the dimensions to bring the time-steps to the front for the next stage.\n",
        "    # (Height, Width, TimeSteps) -> (TimeSteps, Height, Width)\n",
        "    permuted = Permute((3, 1, 2))(temporal_features)  # Shape: (None, 100, 60, 60)\n",
        "\n",
        "    # Reshape to add a 'channels' dimension. Each time-step is now a 60x60x1 image,\n",
        "    # ready to be processed by a 2D CNN.\n",
        "    reshaped = Reshape((100, 60, 60, 1))(permuted)  # Shape: (None, 100, 60, 60, 1)\n",
        "\n",
        "    # --- Part 2: Time-Distributed Spatial Feature Extraction ---\n",
        "\n",
        "    # Define the CNN block that extracts spatial features from a single 60x60 frame.\n",
        "    cnn_block = tf.keras.Sequential([\n",
        "        # Finds low-level features like edges and gradients.\n",
        "        Conv2D(32, kernel_size=(3, 3), padding='same'),\n",
        "        BatchNormalization(),\n",
        "        ReLU(),\n",
        "        # Downsamples the feature map to make representations more robust.\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # Finds higher-level features by combining low-level ones.\n",
        "        Conv2D(64, kernel_size=(3, 3), padding='same'),\n",
        "        BatchNormalization(),\n",
        "        ReLU(),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # Summarizes all spatial features in the frame into a single, fixed-size vector.\n",
        "        GlobalAveragePooling2D()\n",
        "    ], name='internal_cnn_block')\n",
        "\n",
        "    # Apply the defined cnn_block to each of the 100 time-steps independently.\n",
        "    # The output is a sequence of 100 feature vectors, one for each time-step.\n",
        "    time_distributed_cnn = TimeDistributed(cnn_block)(reshaped)  # Shape: (None, 100, 64)\n",
        "\n",
        "    # --- Part 3: Final Transformation ---\n",
        "\n",
        "    # A Dense layer refines the features from the CNN, reducing each feature vector's size to 10.\n",
        "    # It learns combinations of the spatial features.\n",
        "    dense_features = Dense(10, activation='relu')(time_distributed_cnn)  # Shape: (None, 100, 10)\n",
        "\n",
        "    # Final permutation to get the output shape of (Features, TimeSteps).\n",
        "    # This format might be useful for downstream tasks that analyze each feature over time.\n",
        "    final_output = Permute((2, 1))(dense_features)  # Shape: (None, 10, 100)\n",
        "\n",
        "    # Create the final model by defining its inputs and outputs\n",
        "    model = Model(inputs=inputs, outputs=final_output, name='SpatioTemporal_Feature_Extractor')\n",
        "\n",
        "    return model\n",
        "\n",
        "# --- Model Creation, Compilation, and Execution Example ---\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Define the input shape as per the diagram\n",
        "    INPUT_SHAPE = (60, 60, 100)\n",
        "\n",
        "    # Build the model\n",
        "    model = build_spatio_temporal_model(input_shape=INPUT_SHAPE)\n",
        "\n",
        "    # Compile the model. A loss function and optimizer are needed for training.\n",
        "    # For feature extraction, you might not train it, but compilation is a good practice.\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    # Print the model summary to verify the architecture and shapes\n",
        "    print(\"--- Model Summary ---\")\n",
        "    model.summary()\n",
        "\n",
        "    # --- Example of running the model with dummy data ---\n",
        "    print(\"\\n--- Running a test prediction ---\")\n",
        "    # Create a batch of 2 dummy \"videos\" with random data\n",
        "    dummy_data = np.random.rand(2, *INPUT_SHAPE)\n",
        "\n",
        "    # Get the model's prediction\n",
        "    predictions = model.predict(dummy_data)\n",
        "\n",
        "    # Print the shape of the output to confirm it matches the design\n",
        "    print(f\"Input data shape: {dummy_data.shape}\")\n",
        "    print(f\"Final output shape: {predictions.shape}\")\n"
      ],
      "metadata": {
        "id": "o0hhgiZvNFMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jdB7R5zWN5jK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}