{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/Mahdi-Miri/Signal_Proccesing-/blob/main/Signal_Proccesing.ipynb",
      "authorship_tag": "ABX9TyOVfEMRXW+yq1+unUyzFA7D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahdi-Miri/Signal_Proccesing/blob/main/Signal_Proccesing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Readig"
      ],
      "metadata": {
        "id": "FTuvlrstUHeC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "ec8fe35a",
        "outputId": "a630dce8-173d-42e1-905c-7d8b5ebfdaa0"
      },
      "source": [
        "!pip install obspy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting obspy\n",
            "  Downloading obspy-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.12/dist-packages (from obspy) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.12/dist-packages (from obspy) (1.16.2)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.12/dist-packages (from obspy) (3.10.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from obspy) (5.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from obspy) (75.2.0)\n",
            "Collecting sqlalchemy<2 (from obspy)\n",
            "  Downloading SQLAlchemy-1.4.54-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from obspy) (4.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from obspy) (2.32.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->obspy) (2.9.0.post0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<2->obspy) (3.2.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->obspy) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->obspy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->obspy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->obspy) (2025.10.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->obspy) (1.17.0)\n",
            "Downloading obspy-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SQLAlchemy-1.4.54-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sqlalchemy, obspy\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.43\n",
            "    Uninstalling SQLAlchemy-2.0.43:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.43\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.54 which is incompatible.\n",
            "google-adk 1.14.1 requires sqlalchemy<3.0.0,>=2.0, but you have sqlalchemy 1.4.54 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed obspy-1.4.2 sqlalchemy-1.4.54\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "signal"
                ]
              },
              "id": "d204970d78ff4b65b6448dff907e7674"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelling"
      ],
      "metadata": {
        "id": "3yqHTrHlNELT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, BatchNormalization, ReLU, MaxPooling2D,\n",
        "    GlobalAveragePooling2D, TimeDistributed, Dense, Permute, Reshape, Layer\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "xw-UFeFjNI11"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Custom Layer Definition with Functional Implementation ---\n",
        "# This layer now has a functional implementation based on the\n",
        "# Auto-Correlation mechanism using Fast Fourier Transform (FFT).\n",
        "class CustomAutocorrelationLayer(Layer):\n",
        "    \"\"\"\n",
        "    A custom layer that calculates the temporal auto-correlation of an input tensor.\n",
        "    It operates on the last axis, which is assumed to be the time dimension.\n",
        "    The calculation is performed efficiently in the frequency domain using FFT.\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(CustomAutocorrelationLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # The input shape is expected to be (Batch, Height, Width, TimeSteps)\n",
        "        # We need to compute auto-correlation along the TimeSteps axis (axis=-1).\n",
        "\n",
        "        # Get the length of the time series\n",
        "        sequence_length = tf.shape(inputs)[-1]\n",
        "\n",
        "        # --- Step 1: Go to Frequency Domain using FFT ---\n",
        "        # Perform Fast Fourier Transform. tf.signal.rfft is used for real-valued inputs.\n",
        "        # The length of the FFT is padded to the next power of 2 for efficiency,\n",
        "        # but for simplicity, we'll use the original length here.\n",
        "        fft_result = tf.signal.rfft(inputs, fft_length=[sequence_length])\n",
        "\n",
        "        # --- Step 2: Compute Power Spectral Density ---\n",
        "        # This is where the correlation is calculated.\n",
        "        # It's done by multiplying the FFT result by its complex conjugate.\n",
        "        # This is equivalent to convolution in the time domain.\n",
        "        power_spectral_density = fft_result * tf.math.conj(fft_result)\n",
        "\n",
        "        # --- Step 3: Go back to Time Domain using Inverse FFT ---\n",
        "        # Perform Inverse Real Fast Fourier Transform to get the auto-correlation series.\n",
        "        autocorr_result = tf.signal.irfft(power_spectral_density, fft_length=[sequence_length])\n",
        "\n",
        "        return autocorr_result\n",
        "\n",
        "    def get_config(self):\n",
        "        # Required for model saving and loading\n",
        "        config = super(CustomAutocorrelationLayer, self).get_config()\n",
        "        return config\n",
        "\n",
        "# --- Full Architecture Definition ---\n",
        "def build_spatio_temporal_model(input_shape=(60, 60, 100)):\n",
        "    \"\"\"\n",
        "    Builds the complete Spatio-Temporal feature extraction model based on the diagram.\n",
        "\n",
        "    Args:\n",
        "        input_shape (tuple): The shape of the input data (Height, Width, TimeSteps).\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: The compiled Keras model.\n",
        "    \"\"\"\n",
        "    # Define the input layer for our spatio-temporal data\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # --- Part 1: Temporal Transformation & Reshaping ---\n",
        "\n",
        "    # Apply the functional autocorrelation layer to find temporal patterns.\n",
        "    # This layer processes each spatial point's time series (60x60 series of length 100).\n",
        "    # Output values now represent the strength of temporal correlations.\n",
        "    temporal_features = CustomAutocorrelationLayer()(inputs)  # Shape: (None, 60, 60, 100)\n",
        "\n",
        "    # Permute the dimensions to bring the time-steps to the front for the next stage.\n",
        "    # (Height, Width, TimeSteps) -> (TimeSteps, Height, Width)\n",
        "    permuted = Permute((3, 1, 2))(temporal_features)  # Shape: (None, 100, 60, 60)\n",
        "\n",
        "    # Reshape to add a 'channels' dimension. Each time-step is now a 60x60x1 image,\n",
        "    # ready to be processed by a 2D CNN.\n",
        "    reshaped = Reshape((100, 60, 60, 1))(permuted)  # Shape: (None, 100, 60, 60, 1)\n",
        "\n",
        "    # --- Part 2: Time-Distributed Spatial Feature Extraction ---\n",
        "\n",
        "    # Define the CNN block that extracts spatial features from a single 60x60 frame.\n",
        "    cnn_block = tf.keras.Sequential([\n",
        "        # Finds low-level features like edges and gradients.\n",
        "        Conv2D(32, kernel_size=(3, 3), padding='same'),\n",
        "        BatchNormalization(),\n",
        "        ReLU(),\n",
        "        # Downsamples the feature map to make representations more robust.\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # Finds higher-level features by combining low-level ones.\n",
        "        Conv2D(64, kernel_size=(3, 3), padding='same'),\n",
        "        BatchNormalization(),\n",
        "        ReLU(),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # Summarizes all spatial features in the frame into a single, fixed-size vector.\n",
        "        GlobalAveragePooling2D()\n",
        "    ], name='internal_cnn_block')\n",
        "\n",
        "    # Apply the defined cnn_block to each of the 100 time-steps independently.\n",
        "    # The output is a sequence of 100 feature vectors, one for each time-step.\n",
        "    time_distributed_cnn = TimeDistributed(cnn_block)(reshaped)  # Shape: (None, 100, 64)\n",
        "\n",
        "    # --- Part 3: Final Transformation ---\n",
        "\n",
        "    # A Dense layer refines the features from the CNN, reducing each feature vector's size to 10.\n",
        "    # It learns combinations of the spatial features.\n",
        "    dense_features = Dense(10, activation='relu')(time_distributed_cnn)  # Shape: (None, 100, 10)\n",
        "\n",
        "    # Final permutation to get the output shape of (Features, TimeSteps).\n",
        "    # This format might be useful for downstream tasks that analyze each feature over time.\n",
        "    final_output = Permute((2, 1))(dense_features)  # Shape: (None, 10, 100)\n",
        "\n",
        "    # Create the final model by defining its inputs and outputs\n",
        "    model = Model(inputs=inputs, outputs=final_output, name='SpatioTemporal_Feature_Extractor')\n",
        "\n",
        "    return model\n",
        "\n",
        "# --- Model Creation, Compilation, and Execution Example ---\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Define the input shape as per the diagram\n",
        "    INPUT_SHAPE = (60, 60, 100)\n",
        "\n",
        "    # Build the model\n",
        "    model = build_spatio_temporal_model(input_shape=INPUT_SHAPE)\n",
        "\n",
        "    # Compile the model. A loss function and optimizer are needed for training.\n",
        "    # For feature extraction, you might not train it, but compilation is a good practice.\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    # Print the model summary to verify the architecture and shapes\n",
        "    print(\"--- Model Summary ---\")\n",
        "    model.summary()\n",
        "\n",
        "    # --- Example of running the model with dummy data ---\n",
        "    print(\"\\n--- Running a test prediction ---\")\n",
        "    # Create a batch of 2 dummy \"videos\" with random data\n",
        "    dummy_data = np.random.rand(2, *INPUT_SHAPE)\n",
        "\n",
        "    # Get the model's prediction\n",
        "    predictions = model.predict(dummy_data)\n",
        "\n",
        "    # Print the shape of the output to confirm it matches the design\n",
        "    print(f\"Input data shape: {dummy_data.shape}\")\n",
        "    print(f\"Final output shape: {predictions.shape}\")\n"
      ],
      "metadata": {
        "id": "o0hhgiZvNFMF",
        "outputId": "67ff3724-aa50-4f4a-ede5-065bda6aa2b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Model Summary ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"SpatioTemporal_Feature_Extractor\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"SpatioTemporal_Feature_Extractor\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ custom_autocorrelation_layer    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mCustomAutocorrelationLayer\u001b[0m)    │ \u001b[38;5;34m100\u001b[0m)                   │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ permute (\u001b[38;5;33mPermute\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│                                 │ \u001b[38;5;45mNone\u001b[0m)                  │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m1\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m19,200\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │           \u001b[38;5;34m650\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ permute_1 (\u001b[38;5;33mPermute\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ custom_autocorrelation_layer    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomAutocorrelationLayer</span>)    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                   │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ permute (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│                                 │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                  │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,200</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ permute_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,850\u001b[0m (77.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,850</span> (77.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,658\u001b[0m (76.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,658</span> (76.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running a test prediction ---\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step\n",
            "Input data shape: (2, 60, 60, 100)\n",
            "Final output shape: (2, 10, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sYcebQYynz8t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##testing"
      ],
      "metadata": {
        "id": "dmn17kIoqnYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from obspy.clients.fdsn import Client\n",
        "client = Client(\"IRIS\")  # Initialize Client to download data from IRIS\n",
        "import glob\n",
        "from scipy.signal import iirnotch, filtfilt\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from obspy.core import UTCDateTime, read, Stream\n",
        "from obspy.core.inventory.inventory import read_inventory"
      ],
      "metadata": {
        "id": "iWEJwDo7RuWH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def date_maker(year, month, day,hour, minute, second):\n",
        "    year = str(int(year))\n",
        "    month = str(int(month))\n",
        "    day = str(int(day))\n",
        "    hour = str(int(hour))\n",
        "    minute = str(int(minute))\n",
        "    second = str(int(second))\n",
        "\n",
        "    if len(month) == 1:\n",
        "        month = '0' + month\n",
        "    if len(day) == 1:\n",
        "        day = '0' + day\n",
        "    if len(hour) == 1:\n",
        "        hour = '0' + hour\n",
        "    if len(minute) == 1:\n",
        "        minute = '0' + minute\n",
        "    if len(second) == 1:\n",
        "        second = '0' + second\n",
        "\n",
        "    YMDHMS = year + \"-\" + month + \"-\" + day + \"-\" + hour + \"-\" + minute + \"-\" + second\n",
        "    return YMDHMS"
      ],
      "metadata": {
        "id": "89DvFhzaRpnh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_spectrum(data, sampling_rate, title):\n",
        "    n = len(data)\n",
        "    fft_data = np.fft.rfft(data)\n",
        "    freqs = np.fft.rfftfreq(n, 1 / sampling_rate)\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(freqs, np.abs(fft_data))\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Frequency (Hz)\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "6D3IOvLURvhW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = \"GH\"\n",
        "# station_list = ['AKOS', 'KLEF', 'KUKU', 'MRON']\n",
        "station_list = ['AKOS']\n",
        "YMDHMS = date_maker(2013, 1, 1, 0, 0, 0.0)\n",
        "Main_direc = \"./Waveforms/\"\n",
        "st = read(\"/content/drive/MyDrive/Signal/2013-01-01-00-00-00.mseed\")\n",
        "st.plot()\n",
        "start_time = UTCDateTime(2013, 1, 1, 0, 0, 0.0)\n",
        "xml_dir = \"/content/drive/MyDrive/Signal/\"\n",
        "xml_files = glob.glob(os.path.join(xml_dir, \"*.xml\"))\n",
        "inventory = None"
      ],
      "metadata": {
        "id": "G_lV7SPXRxdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for xml_file in xml_files:\n",
        "    inv = read_inventory(xml_file)\n",
        "    if inventory is None:\n",
        "        inventory = inv\n",
        "    else:\n",
        "        inventory += inv"
      ],
      "metadata": {
        "id": "LukqqJSAR0-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_filt = (2, 4, 40.0, 50.0)"
      ],
      "metadata": {
        "id": "HkWuBFEYR4Vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for station in station_list:\n",
        "    print(station)\n",
        "    for day in range(30):  # Adjust the range as per the actual number of days\n",
        "        print(day)\n",
        "        day_start = start_time + day * 86400  # 86400 seconds in a day\n",
        "        day_end = day_start + 86400\n",
        "        st_day = st.select(station=station).slice(starttime=day_start, endtime=day_end)\n",
        "        # st_day.remove_response(inventory=inventory, pre_filt=pre_filt)\n",
        "        # savemat('/home/shazam/Tokyo/Ghana_Collaboration/Matlab_codes/day_data_remove_response.mat', {'day_data_remove_response': st_day.traces[0].data})\n",
        "        # st_day.detrend(\"spline\", order=3, dspline=500)\n",
        "        sampling_rate = st.traces[0].stats.sampling_rate\n",
        "        # freq = 6.05  # Frequency to remove\n",
        "        # df = 0.5  # Width of the notch (0.5 Hz range for fine removal)\n",
        "        # freqmin = freq - df / 2.0\n",
        "        # freqmax = freq + df / 2.0\n",
        "        # Initialize a stream for stacking the daily PACs\n",
        "        daily_pac_stack = Stream()\n",
        "        for hour in range(24):\n",
        "            print(hour)\n",
        "            hour_start = day_start + hour * 3600  # 3600 seconds in an hour\n",
        "            hour_end = hour_start + 3600\n",
        "            st_hour = st_day.slice(starttime=hour_start, endtime=hour_end)\n",
        "            # st_hour.detrend(\"spline\", order=5, dspline=1000)\n",
        "            try:\n",
        "                st_hour.detrend(\"spline\", order=5, dspline=1000)\n",
        "            except ValueError as e:\n",
        "                if \"Interior knots t must satisfy Schoenberg-Whitney conditions\" in str(e):\n",
        "                    print(f\"Skipping iteration due to spline error: {e}\")\n",
        "                    continue  # Skip this iteration and proceed with the next one\n",
        "                else:\n",
        "                    raise  # If it's a different ValueError, re-raise it\n",
        "            st_hour.filter(\"highpass\", freq=1.3, corners=3, zerophase=True)\n",
        "            # st_hour.filter(\"lowpass\", freq=13, corners=3, zerophase=True)\n",
        "            while True:\n",
        "                n = len(st_hour.traces[0].data)\n",
        "                dt = st_hour.traces[0].stats.delta  # Sampling interval\n",
        "                freqs = np.fft.rfftfreq(n, dt)  # Frequency array\n",
        "                fft_vals = np.fft.rfft(st_hour.traces[0].data)  # Fourier transform\n",
        "                amplitude = np.abs(fft_vals)\n",
        "                max_index = np.argmax(amplitude[0:45000])\n",
        "                notch_freq = freqs[max_index]\n",
        "                quality_factor = 30  # Quality factor (higher value = narrower notch)\n",
        "                sampling_rate = st_hour[0].stats.sampling_rate  # Sampling rate (Hz)\n",
        "                b, a = iirnotch(w0=notch_freq, Q=quality_factor, fs=sampling_rate)\n",
        "                filtered_stream = st_hour.copy()\n",
        "                for trace in st_hour:\n",
        "                    trace.data = filtfilt(b, a, trace.data)\n",
        "                if 1==1:\n",
        "                    break\n",
        "            if len(st_hour) == 0:\n",
        "                print(f\"Data gap detected for {station} on {day_start}. Skipping this hour.\")\n",
        "                continue\n",
        "            try:\n",
        "                st_hour.remove_response(inventory=inventory, pre_filt=pre_filt)\n",
        "            except ValueError as e:\n",
        "                print(f\"ValueError encountered while processing {station} at hour {hour} on {day_start}: {e}\")\n",
        "                continue  # Skip this hour if there's an error\n",
        "            st_hour.detrend(\"spline\", order=3, dspline=700)"
      ],
      "metadata": {
        "id": "46cwckJTR7sP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}